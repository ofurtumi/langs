{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. - Playing with pre-trained, static embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1)\n",
    "Choose 10 words and find the 5 words that the models think are most similar to\n",
    "those words (the 5 words that have the highest cosine similarity to each of the\n",
    "words you chose). Choose three verbs, three adjectives and four nouns. Are the\n",
    "results the way you would have expected (are these words actually similar to\n",
    "the input word)? Why/why not? Is there a difference between the results of the\n",
    "two models? Which performs better and why do you think that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164386, 301935)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "# Set file names for train and test data\n",
    "corpus_file = datapath('lee_background.cor')\n",
    "\n",
    "model = FastText(vector_size=100)\n",
    "\n",
    "# build the vocabulary\n",
    "model.build_vocab(corpus_file=corpus_file)\n",
    "\n",
    "# train the model\n",
    "model.train(\n",
    "    corpus_file=corpus_file, epochs=model.epochs,\n",
    "    total_examples=model.corpus_count, total_words=model.corpus_total_words,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wv: ['runs', 'running', 'drive', 'ran', 'scamper']\n",
      "ft:   ['runs', 'death', 'In', 'Premier', 'Royal']\n",
      "\n",
      "wv: ['listening', 'listened', 'visit_www.timewarner.com_investors', 'hear', 'Listen']\n",
      "ft:   ['list', 'contested', 'members', 'organisation', 'ministers']\n",
      "\n",
      "wv: ['being', 'tobe', 'are', 'have', 'willbe']\n",
      "ft:   ['whether', 'become', 'became', 'anything', 'not']\n"
     ]
    }
   ],
   "source": [
    "# three verbs word to vec\n",
    "print(\"wv:\", [word[0] for word in wv.most_similar(positive=['run'], topn=5)])\n",
    "print(\"ft:  \", [word[0] for word in model.wv.most_similar(positive=['run'], topn=5)])\n",
    "print()\n",
    "print(\"wv:\", [word[0] for word in wv.most_similar(positive=['listen'], topn=5)])\n",
    "print(\"ft:  \", [word[0] for word in model.wv.most_similar(positive=['listen'], topn=5)])\n",
    "print()\n",
    "print(\"wv:\", [word[0] for word in wv.most_similar(positive=['be'], topn=5)])\n",
    "print(\"ft:  \", [word[0] for word in model.wv.most_similar(positive=['be'], topn=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wv: ['great', 'bad', 'terrific', 'decent', 'nice']\n",
      "ft:   ['issues', 'very', 'whether', 'growing', 'looking']\n",
      "\n",
      "wv: ['good', 'terrible', 'horrible', 'Bad', 'lousy']\n",
      "ft:   ['places', 'than', 'bowling', 'planning', \"company's\"]\n",
      "\n",
      "wv: ['dull', 'uninteresting', 'monotonous', 'bored', 'bland']\n",
      "ft:   ['hearing', 'during', 'bring', 'injuring', 'bringing']\n"
     ]
    }
   ],
   "source": [
    "# three adjectives w2v\n",
    "print(\"wv:\", [word[0] for word in wv.most_similar(positive=['good'], topn=5)])\n",
    "print(\"ft:  \", [word[0] for word in model.wv.most_similar(positive=['good'], topn=5)])\n",
    "print()\n",
    "print(\"wv:\", [word[0] for word in wv.most_similar(positive=['bad'], topn=5)])  \n",
    "print(\"ft:  \", [word[0] for word in model.wv.most_similar(positive=['bad'], topn=5)])  \n",
    "print()\n",
    "print(\"wv:\", [word[0] for word in wv.most_similar(positive=['boring'], topn=5)])\n",
    "print(\"ft:  \", [word[0] for word in model.wv.most_similar(positive=['boring'], topn=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wv: ['vehicle', 'cars', 'SUV', 'minivan', 'truck']\n",
      "ft:   ['carried', 'entered', 'leading', 'continued', 'water']\n",
      "\n",
      "wv: ['dogs', 'puppy', 'pit_bull', 'pooch', 'cat']\n",
      "ft:   ['immediately', 'week.', 'company', 'create', 'department']\n",
      "\n",
      "wv: ['brownies', 'pogi', 'corn_muffins', 'vanilla_cone', 'red_velvet_cupcake']\n",
      "ft:   ['real', 'reduced', 'side', 'decide', 'brought']\n",
      "\n",
      "wv: ['computers', 'laptop', 'laptop_computer', 'Computer', 'com_puter']\n",
      "ft:   ['international', 'leading', 'International', 'supporters', 'enter']\n"
     ]
    }
   ],
   "source": [
    "# four nouns\n",
    "print(\"wv:\", [word[0] for word in wv.most_similar(positive=['car'], topn=5)])\n",
    "print(\"ft:  \", [word[0] for word in model.wv.most_similar(positive=['car'], topn=5)])\n",
    "print()\n",
    "print(\"wv:\", [word[0] for word in wv.most_similar(positive=['dog'], topn=5)])\n",
    "print(\"ft:  \", [word[0] for word in model.wv.most_similar(positive=['dog'], topn=5)])\n",
    "print()\n",
    "print(\"wv:\", [word[0] for word in wv.most_similar(positive=['brownie'], topn=5)])\n",
    "print(\"ft:  \", [word[0] for word in model.wv.most_similar(positive=['brownie'], topn=5)])\n",
    "print()\n",
    "print(\"wv:\", [word[0] for word in wv.most_similar(positive=['computer'], topn=5)])\n",
    "print(\"ft:  \", [word[0] for word in model.wv.most_similar(positive=['computer'], topn=5)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the words using word to vec are similar to the input word, the one weird outlier being 'visit_www.timewarner.com_investors' which also somehow renders as a link?? Fasttext seems to gravitate more towards words that could come before or after or are just include the word as a substring.\n",
    "\n",
    "But the likeness in the words can come from opposites as seen in good for wv which has bad as the second closest word, and bad has good as it's closest word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2)\n",
    "Have the models answer 5 analogy questions (something like king – man + woman = queen). Report your results. Do the models get the questions right?\n",
    "How often is the correct answer within the top 10 most likely words but not the\n",
    "top scoring one? How often does the model not get the question right? What\n",
    "could be the cause of that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['queen', 'monarch', 'princess', 'crown_prince', 'prince', 'kings', 'Queen_Consort', 'queens', 'sultan', 'monarchy']\n",
      "['calling', 'responding', 'trying', 'respond', 'working', 'worked', 'having', 'playing', 'acting', 'losing']\n",
      "\n",
      "['dreaming', 'Thinking', 'daydreaming', 'thinkin', 'spit_balling', 'maybe', 'fantasizing', 'talking', 'Psh', 'Heh_heh']\n",
      "['playing', 'throughout', 'growing', \"don't\", 'making', 'saying', 'staying', 'your', 'through', 'though']\n",
      "\n",
      "['bungalow', 'gardens', 'vegetable_garden', 'patio', 'houses', 'bedroom', 'terrace', 'summerhouse', 'cottage', 'herb_garden']\n",
      "['whose', 'though', 'always', 'received', 'director', 'Another', 'locked', 'receive', 'students', 'lower']\n",
      "\n",
      "['forks', 'forking', 'similarly_specced', 'iWallet', 'Forking', 'forked', 'Macalope', 'Acer_netbook', 'pricetag', 'santoku']\n",
      "['tennis', 'work', 'stage', 'wage', 'treatment', 'recent', 'statement', 'several', 'expressed', 'traditional']\n",
      "\n",
      "['grandchild', 'children', 'chld', 'child_ren', 'collapse_Betsy_Sathers', 'baby', 'chid', 'preschooler', 'newborn', 'toddler']\n",
      "['concerned', 'acting', 'getting', 'calling', 'understanding', 'different', 'threatening', 'starting', 'escalating', 'allegations']\n"
     ]
    }
   ],
   "source": [
    "# king - man + woman = queen\n",
    "print([word[0] for word in wv.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"], topn=10)])\n",
    "print([word[0] for word in model.wv.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"], topn=10)])\n",
    "\n",
    "# monkey - animal + thinking = human\n",
    "print()\n",
    "print([word[0] for word in wv.most_similar(positive=[\"monkey\", \"thinking\"], negative=[\"animal\"], topn=10)])\n",
    "print([word[0] for word in model.wv.most_similar(positive=[\"monkey\", \"thinking\"], negative=[\"animal\"], topn=10)])\n",
    "\n",
    "# house - roof = garden\n",
    "print()\n",
    "print([word[0] for word in wv.most_similar(positive=[\"house\", \"garden\"], negative=[\"animal\"], topn=10)])\n",
    "print([word[0] for word in model.wv.most_similar(positive=[\"house\", \"garden\"], negative=[\"animal\"], topn=10)])\n",
    "\n",
    "# spork - spoon = fork\n",
    "print()\n",
    "print([word[0] for word in wv.most_similar(positive=[\"spork\", \"fork\"], negative=[\"spoon\"], topn=10)])\n",
    "print([word[0] for word in model.wv.most_similar(positive=[\"spork\", \"fork\"], negative=[\"spoon\"], topn=10)])\n",
    "\n",
    "# child + time = adult\n",
    "print()\n",
    "print([word[0] for word in wv.most_similar(positive=[\"child\", \"time\"], topn=10)])\n",
    "print([word[0] for word in model.wv.most_similar(positive=[\"child\", \"time\"], topn=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ég var að muna að ég get svarað á íslensku 😎 \n",
    "\n",
    "Ég hef eiginlega ekki hugmynd um hvað er í gangi hjá fasttext, ég get svona eiginlega giskað á hvað útkoman hjá w2v verði, kannski er það einfaldlega því það er stærra og betra módel, en þó ekki alltaf\n",
    "\n",
    "Þótt ég skilji ekki alveg FT þá finnst mér ehv fallegt við að monkey - animal + thinking hafi útkomuna playing sem líklegasta match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. - Train your own embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fyrst, ólemmuð gögn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "\n",
    "with open('../data/log.txt', 'r', encoding='utf-8') as f:\n",
    "    txt = f.read().split()\n",
    "    mymodel= gensim.models.Word2Vec([txt],min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hlaupa: ['kysst', 'hlekk', 'tállaus', 'Síldarvalsinn', 'slappi']\n",
      "hlusta: ['stórfínt.', 'sólbjörtu', 'skriður.', 'sólarlag', 'flögraði']\n",
      "vera: ['hundruðum', 'ysta', 'flögraði', 'hóglátt', 'dansleikjum']\n",
      "góður: ['blóðið', 'ba-bú,', 'verpir', 'uppfrá', 'ekið']\n",
      "vondur: ['þrír.', 'Blessast', 'Gunna-Stína', 'kryfja', 'Gyða']\n",
      "þreyttur: ['sigldir', 'glaður.', \"gestanna'\", 'himinbaug,', 'Litlar']\n",
      "ferð: ['blysum............', 'húmi,', 'brúðu', 'hjartarótinni.', 'kallaður']\n",
      "hundur: ['tjaldað', 'ballalest-lest-lest,', 'Maja,', 'hamast', 'hestinum']\n",
      "brauð: ['hljóður', 'kæri“.', 'paradís.', 'næst,', 'hiklaust']\n",
      "draumur: ['Jörundar', 'hausti', 'hæðum', 'barnahópur', 'Galar,']\n"
     ]
    }
   ],
   "source": [
    "print(\"hlaupa:\", [ord[0] for ord in mymodel.wv.most_similar(positive=['hlaupa'], topn=5)])\n",
    "print(\"hlusta:\", [ord[0] for ord in mymodel.wv.most_similar(positive=['hlusta'], topn=5)])\n",
    "print(\"vera:\", [ord[0] for ord in mymodel.wv.most_similar(positive=['vera'], topn=5)])\n",
    "print(\"góður:\", [ord[0] for ord in mymodel.wv.most_similar(positive=['góður'], topn=5)])\n",
    "print(\"vondur:\", [ord[0] for ord in mymodel.wv.most_similar(positive=['vondur'], topn=5)])\n",
    "print(\"þreyttur:\", [ord[0] for ord in mymodel.wv.most_similar(positive=['þreyttur'], topn=5)])\n",
    "print(\"ferð:\", [ord[0] for ord in mymodel.wv.most_similar(positive=['ferð'], topn=5)])\n",
    "print(\"hundur:\", [ord[0] for ord in mymodel.wv.most_similar(positive=['hundur'], topn=5)])\n",
    "print(\"brauð:\", [ord[0] for ord in mymodel.wv.most_similar(positive=['brauð'], topn=5)])\n",
    "print(\"draumur:\", [ord[0] for ord in mymodel.wv.most_similar(positive=['draumur'], topn=5)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nú notum við lemmuð gögn sem eru vistuð í ../data/all_lemmas.txt tekið úr verkefni tvö, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/all_lemmas.txt', 'r', encoding='utf-8') as f:\n",
    "    txt = f.read().split()\n",
    "    mylemmas = gensim.models.Word2Vec([txt],min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hlaupa: ['hjarta', 'út', 'margur', 'þú', 'allt']\n",
      "hlusta: ['stjarna', 'bál', 'sár', 'Tra-rí', 'saga']\n",
      "vera: ['og', 'í', 'á', 'að', 'ég']\n",
      "góður: ['hann', 'að', 'ég', 'og', 'í']\n",
      "vondur: ['lyng', 'næturlest', 'fölnaður', 'lífga', 'Arnarhóll']\n",
      "þreytt: ['dans', 'hlæja', 'þessi', 'bara', 'synda']\n",
      "ferð: ['tófa', 'króna', \"líka'\", 'fjallasalur', 'oní']\n",
      "hundur: ['von', 'þegar', 'með', 'ekki', 'segja']\n",
      "brauð: ['kvæði', 'úti', 'ganga', 'sitja', 'barn']\n",
      "draumur: ['þá', 'við', 'og', 'í', '—']\n"
     ]
    }
   ],
   "source": [
    "print(\"hlaupa:\", [ord[0] for ord in mylemmas.wv.most_similar(positive=['hlaupa'], topn=5)])\n",
    "print(\"hlusta:\", [ord[0] for ord in mylemmas.wv.most_similar(positive=['hlusta'], topn=5)])\n",
    "print(\"vera:\", [ord[0] for ord in mylemmas.wv.most_similar(positive=['vera'], topn=5)])\n",
    "print(\"góður:\", [ord[0] for ord in mylemmas.wv.most_similar(positive=['góður'], topn=5)])\n",
    "print(\"vondur:\", [ord[0] for ord in mylemmas.wv.most_similar(positive=['vondur'], topn=5)])\n",
    "print(\"þreytt:\", [ord[0] for ord in mylemmas.wv.most_similar(positive=['þreyttur'], topn=5)])\n",
    "print(\"ferð:\", [ord[0] for ord in mylemmas.wv.most_similar(positive=['ferð'], topn=5)])\n",
    "print(\"hundur:\", [ord[0] for ord in mylemmas.wv.most_similar(positive=['hundur'], topn=5)])\n",
    "print(\"brauð:\", [ord[0] for ord in mylemmas.wv.most_similar(positive=['brauð'], topn=5)])\n",
    "print(\"draumur:\", [ord[0] for ord in mylemmas.wv.most_similar(positive=['draumur'], topn=5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eins og sést meika hvorugar niðurstöðurnar nokkurn sens, það næsta sem kemst því að vera ehv er $ferð -> tófa$ einfaldlega vegna þess að tófur eru alltaf ehv á vappinu en kannski er ég að leita að meiningu þar sem er engin. Þrátt fyrir að lemmunin hafi gert niðurstöðurnar hugsanlega aðeins réttari þá minnkaði líka orðasafnið okkar úr ~80k orðum niður í ~35k sem vinnur líklega á móti hagnaðinum\n",
    "\n",
    "Prófum einu sinni enn og breytum hyper parametrunum aðeins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/all_lemmas.txt', 'r', encoding='utf-8') as f:\n",
    "    txt = f.read().split()\n",
    "    posbetter = gensim.models.Word2Vec([txt],negative=10,min_count=5, vector_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hlaupa: ['nú', 'sinn', 'blár', 'þinn', 'við']\n",
      "hlusta: ['sumur', 'hefja', 'ljóð', 'geyma', 'land']\n",
      "vera: ['með', 'er', 'við', 'hún', 'til']\n",
      "góður: ['hann', 'við', 'sem', 'sig', 'en']\n",
      "vondur: ['þjóðvísa', 'rökkur', 'elli', 'sunna', 'ilmur']\n",
      "þreytt: ['blóm', 'bíða', 'áfram', 'sál', 'heyra']\n",
      "ferð: ['söngur', 'gulur', 'samt', 'lind', 'góður']\n",
      "hundur: ['sérhver', 'mikill', 'eins', 'tíð', 'alltaf']\n",
      "brauð: ['amma', 'er', 'öld', 'leið', 'bær']\n",
      "draumur: ['nótt', 'hún', 'þá', 'sem', 'um']\n"
     ]
    }
   ],
   "source": [
    "print(\"hlaupa:\", [ord[0] for ord in posbetter.wv.most_similar(positive=['hlaupa'], topn=5)])\n",
    "print(\"hlusta:\", [ord[0] for ord in posbetter.wv.most_similar(positive=['hlusta'], topn=5)])\n",
    "print(\"vera:\", [ord[0] for ord in posbetter.wv.most_similar(positive=['vera'], topn=5)])\n",
    "print(\"góður:\", [ord[0] for ord in posbetter.wv.most_similar(positive=['góður'], topn=5)])\n",
    "print(\"vondur:\", [ord[0] for ord in posbetter.wv.most_similar(positive=['vondur'], topn=5)])\n",
    "print(\"þreytt:\", [ord[0] for ord in posbetter.wv.most_similar(positive=['þreyttur'], topn=5)])\n",
    "print(\"ferð:\", [ord[0] for ord in posbetter.wv.most_similar(positive=['ferð'], topn=5)])\n",
    "print(\"hundur:\", [ord[0] for ord in posbetter.wv.most_similar(positive=['hundur'], topn=5)])\n",
    "print(\"brauð:\", [ord[0] for ord in posbetter.wv.most_similar(positive=['brauð'], topn=5)])\n",
    "print(\"draumur:\", [ord[0] for ord in posbetter.wv.most_similar(positive=['draumur'], topn=5)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok bara við það að hækka `min_count` upp í 5 lét okkur hafa niðustöður sem virðast allaveg vera nær því að vera réttar en upphaflegu niðurstöðurnar, þær eru þó frekar lélegar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. - Transformers B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. módel\n",
    "Ég tók 2 ár af spænsku í menntaskóla nú er áhugavert að sjá hvort ég muni ehv af því sem ég lærði.\n",
    "\n",
    "[Módelið](https://huggingface.co/Helsinki-NLP/opus-mt-is-es) er þjálfað á [opus-2020-06-17](https://github.com/Helsinki-NLP/Tatoeba-Challenge/blob/master/models/isl-spa/README.md) og er bæði encoder og decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "is_es_translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-is-es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is: Má ég vinsamlegast fara á klósettið?\n",
      "es: ¿Puedo ir al baño, por favor?\n",
      "\n",
      "is: Góðann daginn, ég heiti Tumi, hvað heitir þú?\n",
      "es: Buenos días, soy Tumi. ¿Cómo te llamas?\n",
      "\n",
      "is: Klukkan er korter yfir 6\n",
      "es: Son las 6:15 de la mañana.\n",
      "\n",
      "is: Ég er 25 ára\n",
      "es: Tengo 25 años.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setning sem ég mun aldrei gleyma: má ég vinsamlegast fara á klósettið? \n",
    "is_sent = [\n",
    "    \"Má ég vinsamlegast fara á klósettið?\",             # puedo ir al bano por favor?\n",
    "    \"Góðann daginn, ég heiti Tumi, hvað heitir þú?\",    # buenos dias, me llamo Tumi, coma te llamas?\n",
    "    \"Klukkan er korter yfir 6\",                         # las hora es seis i cuarto\n",
    "    \"Ég er 25 ára\",                                     # tengo viente y cinco anos\n",
    "]\n",
    "\n",
    "for es_sent in is_sent:\n",
    "    print(f\"is: {es_sent}\\nes: {is_es_translator(es_sent)[0]['translation_text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nú er spurning hvort er að bregðast mín spænskukunnátta úr menntaskóla eða módelið, ég set peninginn á mig en ég ætla þó að henda þessum setningum í gegnum translate til að vera viss.\n",
    "\n",
    "- Samkvæmt translate er fyrsta rétt, ég vissi það.\n",
    "- Samkvæmt translate höfum bæði ég og módelið rangt fyrir okkur, en ég er samt eiginlega viss um að báðar þýðingar séu réttar \"soy Tumi\" þýðir samt eiginlega \"ég er Tumi\" en hægt að nota það fyrir \"ég heiti\"\n",
    "- Þarf ekki að setja í gegnum translate til að vita að þetta \"de la manana\" ætti ekki að vera þarna, það er kannski líklegt að ég sé að tala um \"6 um morguninn\" en ég sagði það ekki, auk þess finnst mér skræfu move að nota tölustafi\n",
    "- Þetta er gilt en eins og fyrir ofan finnst mér pínu leiðinlegt að notaðir séu tölustafir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is: vinur minn gunnar er að drekka gos -> es: Mi amigo está bebiendo refresco\n"
     ]
    }
   ],
   "source": [
    "is_input = input(\"Sláðu inn íslensku setningu: \")\n",
    "print(f\"is: {is_input} -> es: {is_es_translator(is_input)[0]['translation_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. módel\n",
    "[Þetta módel](https://huggingface.co/vesteinn/XLMr-ENIS-QA-Is) var sýnt í tíma\n",
    "\n",
    "Það er byggt á þýddum enskum gagnasöfnum ásamt gagnasafni um eðlilegar íslenskar spurningar. Það stendur ekki en ég reikna með að það noti bæði encoder, fyrir input, og decoder fyrir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "qa = pipeline(\"question-answering\", \"vesteinn/XLMr-ENIS-QA-Is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: Hver er Þorvaldur Tumi?\n",
      "a:  Ég er að læra tölvunarfræði\n",
      "\n",
      "q: Hver er Þorvaldur Tumi Baldursson?\n",
      "a: Halló halló,\n",
      "\n",
      "q: Hvað er Tumi að læra?\n",
      "a:  tölvunarfræði\n",
      "\n",
      "q: Hver eru helstu forritunarmál Tuma?\n",
      "a:  framendaforritun\n",
      "\n",
      "q: Í hvaða tungumálum hefur Tumi mesta reynslu?\n",
      "a:  verkefnum,\n",
      "\n",
      "q: Hvaða tungumál má nefna sem Tumi hefur ágæta reynslu í?\n",
      "a:  nokkrum\n",
      "\n",
      "q: Hvað eru fleiri tungumál sem Tumi hefur snert á?\n",
      "a:  R, haskell og Zig.\n",
      "\n",
      "q: Hvað er Tumi gamall?\n",
      "a:  22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ég nota hérna aðeins breyttan kynningar texta af heimasíðunni minni sem context\n",
    "qa_context = \"Halló halló, Þorvaldur Tumi heiti ég og er 22 árs gamall. Ég er að læra tölvunarfræði með fókus á framendaforritun og hef unnið í nokkrum fullstack verkefnum, bæði einn og með með teymi. Mér finnst gaman að birta það sem ég er að vinna í og hef mikið dálæti af því að búa til sýnidæmi og kennsluefni sem aðrir gætu haft gagn eða gaman af því að skoða. Ég hef ágætis reynslu í mörgum tungumálum, þar má nefna C, C++, java, javascript / typescript, rust og python, auk þeirra hef ég snert á fleiri málum eins og R, haskell og Zig.\"\n",
    "\n",
    "\n",
    "qa_sent = [\n",
    "    \"Hver er Þorvaldur Tumi?\",\n",
    "    \"Hver er Þorvaldur Tumi Baldursson?\",\n",
    "    \"Hvað er Tumi að læra?\",\n",
    "    \"Hver eru helstu forritunarmál Tuma?\",\n",
    "    \"Í hvaða tungumálum hefur Tumi mesta reynslu?\",\n",
    "    \"Hvaða tungumál má nefna sem Tumi hefur ágæta reynslu í?\",\n",
    "    \"Hvað eru fleiri tungumál sem Tumi hefur snert á?\",\n",
    "    \"Hvað er Tumi gamall?\",\n",
    "]\n",
    "\n",
    "for question in qa_sent:\n",
    "    print(f\"q: {question}\\na: {qa(question=question, context=qa_context)['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nú er það líklega biasinn minn eftir að hafa notað Chat-GPT helling en ég hélt að módelið yrði betra í að svara spurningunum. Eins og sést fyrir ofan eru ekki nema alveg hnitimiðuðustu spurningunum svarað rétt. Textinn minn gæti þó líka verið að sök hér þannig ég ætla prófa aftur með stærra context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: Hverjir eru helstu flokkar vætta í íslenskum þjóðsögum?\n",
      "a:  tröll.\n",
      "\n",
      "q: Voru Djáknin og Guðrún á góðum nótum áður en hann dó?\n",
      "a:  draugasaga, djákninn og Guðrún eru á góðum nótum\n",
      "\n",
      "q: Hver er þekkstasta tröllskessa í íslenskum þjóðsögum?\n",
      "a:  Gilitrutt\n",
      "\n",
      "q: Hver er helsti tilgangur drauga og afturganga í íslenskum þjóðsögum?\n",
      "a:  að hrella manneskjur sem voru nánar þeim í lífinu.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ritgerð sem ég gerði í íslensku á 2. ári í menntaskóla um vætti og verur í íslenskum þjóðsögum\n",
    "qa_context = \"Íslenskar þjóðsögur innihalda margar hverjar einhverskonar yfirnáttúrulega vætti eða verur. Hægt er að spyrja sig hvers konar vættir eru í íslenskum þjóðsögum og hvaða hlutverki gegna þeir. Í þessari ritgerð verður litið á vætti úr völdum íslenskum þjóðsögum og farið yfir tilgang þeirra og hegðun. Þjóðsögur hafa fylgt íslensku þjóðinni í aldanna rás. „Hugtakið þjóðsaga er notað um frásagnir sem lengi hafa gengið í munnmælum meðal alþýðu manna, sumar öldum saman.“. Ragnhildur Richter o.fl. 2014:224 Eins og kemur fram í kennslubókinni íslenska fjögur voru margar af vinsælustu íslensku þjóðsögunum teknar saman á rómantíska tímabilinu. Safnað var saman mörgum íslenskum þjóðsögum og þær skráðar niður í anda rómantískra hugmynda. Hugmyndina að safna saman þjóðsögum er hægt að rekja til Grimm bræðranna, Jakobs og Wilhelms Grimm. Þeir gáfu út þekkta sögusafnið „Grimms ævintýri“ snemma á 19. öld og eftir það fylgdu margir fræðimenn í fótspor bræðranna og söfnuðu sínum þjóðsögum saman. Þjóðsögur voru oft uppspuni frá byrjun til enda en það varlíka þekkt að þjóðsögur væru byggðar í kring um einhvern eða einhverja sannsögulega atburði. Þjóðsögur voru líka notaðar sem tól til að útskýra hið óútskýranlega eins og mikla heppni eða harðan vetur og ef uppskeran var lítil var það ekki vegna þess að illa var ræktað heldur vegna þess að einhver hafði gert álfa reiða eða eitthvað álíka. Íslenskar þjóðsögur enduðu oftast á tvo vegu, annaðhvort endaði aðalpersónan verr sett en fyrir atburði sögunnar, dauð eða geðveik eða hún endaði betur sett en hún var fyrir atburði sögunnar, rík og glöð. Þetta er ljóst um leið og maður byrjar að lesa þjóðsögur. Sögurnar innihalda vætti af öllum stærðum og gerðum og í flestum tilfellum er hægt að flokka þá í tvennt, góða eða vonda vætti. Góðir vættir vilja oftast vel og hjálpa sögupersónum að ná sínu fram eða til þess að bæta stöðu sína, oft með yfirnáttúrulegum eða óútskýranlegum hætti. Dæmi um vætt sem hjálpar sögupersónunni að komast á betri stað er sagan „Þá hló marbendill“. Í þeirri sögu er aðal sögupersónan að veiða og veiðir marbendil óvart. Marbendlinum líst ekkert á það og biður manninn um að sleppa sér en þegar maðurinn vill það ekki hættir marbendill að tala. Þrisvar sinnum í sögunni hlær marbendill að einhverju sem er að gerast og maðurinn verður forvitinn og vill vita  af hverju. Marbendill segist ekki muni segja af hverju hann hló nema honum verði sleppt aftur þar sem hann var veiddur. Maðurinn fellst á það og marbendill segir honum frá hlutum sem hann gat ekki vitað nema á einhvern yfirnáttúrulegan hátt. Þegar maðurinn er búinn að ganga úr skugga um sannindi þess sem marbendill sagði sleppir hann marbendlinum. Í sögunni græddu báðir aðilar. Maðurinn fékk gull sem marbendill sagði honum frá auk kúa sem marbendill sendi honum eftir að hafa verið sleppt og marbendill komst aftur heim og er þannig betur settur en á horfðist í byrjun sögunnar   Vondir vættir eru andstæðurnar við þá góðu. Vondir vættir reyna að skemma fyrir sögupersónum, stundum hafa þeir ástæðu til að gera það en stundum að ástæðulausu. Gott dæmi um vondan vætt með ástæðu fyrir gjörðum sínum er sagan um Gilitrutt. Í henni gerir húsfreyja samkomulag við skessu um að vinna verk fyrir sig fyrir laun sem skessan ákvarðar. Launin eru að húsfreyja þarf að geta nafn skessunnar innann þriggja tilrauna þegar þær hittast næst. Ef húsfreyja getur ekki uppfyllt skilyrði samkomulagsins er gefið í skyn að skessan muni éta hana. Þarna er skessan vondur vættur en hefur ástæðu til að gera það sem hún gerir vegna þess að skessan og húsfreyja gerðu samkomulag.   Stundum er ekkert sérstakt sem ýtir undir hegðun vætta og þeir gera sögupersónum bara illt vegna þess að þeir eru vondir í eðli sínu. Dæmi um sögu þar sem vættur er vondur í eðli sínu er sagan um djáknann á Myrká. Sagan gerist í Eyjafirði og segir frá tveimur manneskjum, djákna í sveitinni og konu sem hét Guðrún, þau voru í sambandi. Djákninn er að ferðast en kemst ekki á leiðarenda., Bóndi í sveitinni finnur hann látinn en fréttir af dauða hans berast ekki til bæjarins þar sem Guðrún er. Á aðfangadag fór Guðrún að Myrká til að taka þátt í skemmtun sem var þar. Þegar Guðrún býr sig undir að fara er barið að dyrum og þegar Guðrún fer til að athuga sér hún hest djáknans auk manns sem hún telur að sé djákninn og sest á bak hestsins. Þegar hesturinn hnýtur sér Guðrún hnakka djáknans sem og bregður þegar hún sér í bera höfuðkúpuna. Þau ríða að opinni gröf og Guðrún verður svakalega hrædd og byrjar að hringja kirkjubjöllum. Djákninn hélt áfram að ásækja Guðrúnu á kvöldin þangað til galdramaður er fenginn til að særa niður djáknann. Sagan er dæmigerð draugasaga, djákninn og Guðrún eru á góðum nótum áður en hann deyr en um leið og þau hittast eftir dauða hans breytist það. Draugar eiga að vera vondir og djákninn fylgir því þrátt fyrir að hafa ekkert á móti Guðrúnu áður en hann deyr. Eina markmið hans er að vera illur í garð Guðrúnar. Hægt er að skipta flestum þjóðsagnavættum í hópa út frá gjörðum þeirra en þeim er líka hægt að skipta niður fleiri meginflokka. Þessir flokkar eru samt bara regnhlífar yfir hundruði vætta og vera í íslenskum þjóðsögum Einn flokkur vætta i íslenskum þjóðsögum eru tröll. Tröll eru stór og klunnaleg en geta þó verið mjög klár þrátt fyrir útlit sitt. Tröll eru þekkt fyrir það að borða fólk og eiga það til að setja fram gátur til að blekkja eða lokka fólk til sín svo að tröllin geti étið þau. Ein af þekktustu þjóðsagnakenndu tröllskessum landsins er Gilitrutt sem lét giska á nafnið sitt. Draugar og afturgöngur eru annar stór flokkur. Eins og tröllin eru þessir vættir oftast ekki að leitast eftir því að vera góðir við persónur sagnanna sem þeir tilheyra. Draugar og afturgöngur eiga það gjarnan til að hrella manneskjur sem voru nánar þeim í lífinu. Dæmi um afturgöngu í sögu er Miklabæjar Sólveig, kona sem sturlaðist þegar maðurinn sem hún elskaði vildi hana ekki. Hún tekur sitt eigið líf og gengur aftur til þess að reyna að drepa manninn sem hún eitt sinn elskaði. Henni tekst það og þegar fólkið í kringum manninn reyndi að finna út hvað hafði gerst fór hún á eftir þeim líka og ógnaði þeim í draumum . Eftir það var hætt að reyna finna út hvað hafði komiðfyrir manninn og ekkert heyrðistaf Sólveigu fyrr en sonur mannsins ætlaði að sofa hjá konu sinni í fyrsta skiptið  en þá ásótti Sólveig hann, sem reyndar náði að halda henni í skefjum. Huldufólk og álfar eru þriðji af stærstu flokkum vætta í íslenskum þjóðsögum. Erfitt er að flokka hegðun álfa og huldufólks niður í gott eða vont vegna þess að hegðun þeirra endurspeglast alveg í því hvernig komið fram er við þá. Álfar eru fínir, vitrir og friðsælir svo lengi sem komið er fram við þá af virðingu. Gott dæmi um skap álfa er sagan um Helgu bóndadóttur og álfana. Helga er stelpa sem er lítilsvirt af fjölskyldunni sinni. Hún er skilin eftir ein heima á aðfangadagskvöld til að passa bæinn og mjólka kýrnar. Allir sem hafa verið eftir einir á þessum tíma á þessum bæ hafa fundist látnir daginn eftir en mamma Helgu segir að í hennar tilviki  skipti það ekki máli þar sem enginn muni sakna hennar. Um kvöldið þegar hún er ein kemur barn inn í eldhúsið þar sem Helga er að elda, barnið biður um smá bita af mat og Helga gefur því mat þrátt fyrir að móðir hennar hafi bannað henni að fá sér af matnum. Barnið þakkar fyrir sig og fer. Seinna um kvöldið kemur hellingur af fólki sem Helga kannaðist ekki við inn á bæinn en Helga lætur þau í friði og þau koma fram við hana af virðingu á móti. Helga fer út til að  mjólka kúna og þá kemur  maður upp að henni og biður um að sofa hjá henni. Helga þvertekur fyrir það þangað til hann fer. Skömmu seinna kemur kona inn að þakka Helgu fyrir góðverk sín, að gefa barninu að borða og neita manninum, og gefur henni falleg föt og belti auk loforðs um að einn daginn muni hún giftast biskupi og vera gæfukona. Daginn eftir sjá móðir og systir Helgu gjafirnar og vilja eignast þær en Helga vill það ekki. Ári seinna verður móðir Helgu eftir til að reyna að eignast gjafir eins og þær sem Helga fékk. Þegar barnið kemur og biður móðurina um mat brjálast hún og slær til þess og brýtur á því hendina. Þegar fólk kemur aftur að bænum sér það móðurina barða og blóðuga og hún segir frá því sem gerðist og deyr svo. Í sögunni kom Helga fram við alla af virðingu, gjafmildi og  kurteisi. Álfunum leist vel á það og verðlaunuðu hana með gjöfum og góðu lífi. En móðirin sem kom fram við barnið með dónaskap og ofbeldi fékkþað sem hún gaf til baka og var barin til dauða. Í þessari sögu má sjá náttúru álfa og huldufólks á skýran hátt.  Það er greinilegt að vættir gegna stóru hlutverki í þjóðsögum á íslandi og í öðrum löndum. Í gegn um tíðina hafa vættir verið notaðir til þess að útskýra skrítna atburði og það sem fólk gat ekki útskýrt á aðra vegu. \"\n",
    "\n",
    "qa_sent = [\n",
    "    \"Hverjir eru helstu flokkar vætta í íslenskum þjóðsögum?\",\n",
    "    \"Voru Djáknin og Guðrún á góðum nótum áður en hann dó?\",\n",
    "    \"Hver er þekkstasta tröllskessa í íslenskum þjóðsögum?\",\n",
    "    \"Hver er helsti tilgangur drauga og afturganga í íslenskum þjóðsögum?\",\n",
    "    \"Hverjir gáfu út Grimms Ævintýri?\",\n",
    "]\n",
    "\n",
    "for question in qa_sent:\n",
    "    print(f\"q: {question}\\na: {qa(question=question, context=qa_context)['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talsvert betri svör núna, greinilegt að það er magn textans sem skiptir meira máli en gæðin því vá þessi ritgerð er ekki góð."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: Hver er Gilitrutt\n",
      "a:  Ein af þekktustu þjóðsagnakenndu tröllskessum landsins\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = input(\"Hvað viltu vita um íslenskar þjóðsögur?\")\n",
    "\n",
    "print(f\"q: {q}\\na: {qa(question=q, context=qa_context)['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. módel\n",
    "Þetta módel er byggt ofaná [mt5](https://huggingface.co/google/mt5-base) módel frá google sem sérhæfir sig í að súmmera texta og síðan sérþjálfað á gögnum frá Rúv\n",
    "\n",
    "Módelið notar bæði encoding og decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"thors/mt5-base-icelandic-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Halló Hallósson, 22, er að læra tölvunarfræði með fókus á framendaforritun. Hann hefur ágætis reynslu í mörgum tungumálum og hefur einnig snert á fleiri málum.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"Halló halló, Þorvaldur Tumi heiti ég og er 22 árs gamall. Ég er að læra tölvunarfræði með fókus á framendaforritun og hef unnið í nokkrum fullstack verkefnum, bæði einn og með með teymi. Mér finnst gaman að birta það sem ég er að vinna í og hef mikið dálæti af því að búa til sýnidæmi og kennsluefni sem aðrir gætu haft gagn eða gaman af því að skoða. Ég hef ágætis reynslu í mörgum tungumálum, þar má nefna C, C++, java, javascript / typescript, rust og python, auk þeirra hef ég snert á fleiri málum eins og R, haskell og Zig.\"\n",
    "\n",
    "summarizer(context)[0]['summary_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Módelið er þjálfað á fréttum frá RÚV þannig útkoman sem það gefur meikar sens þrátt fyrir að vera ekki endilega það sem ég hefði búist við. Þetta er skemmtilegt módel og væri auðvelt að nýta það  Ég prófa þetta aftur með alvöru frétt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mótmæli gegn sjókvíaeldi fóru fram á Austurvelli í dag. Bændur og landeigendur keyra alls staðar af á landinu og fylkja liði niður á Austurvöll.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\"Mótmæli gegn sjókvíaeldi fóru fram á Austurvelli í dag. Eflt var til óvenjulegs gjörnings að mótmælunum loknum þegar „lúsaeitri“ var hellt yfir Austurvöll og yfir dauða fiska við Alþingishúsið. Í tilkynningu segir að bændur og landeigendur muni keyra alls staðar af á landinu og fylkja liði niður á Austurvöll. Gengið verður frá bílastæði Háskóla Íslands að Austurvelli þar sem mótmælin fara fram.Árni Pétur Hilmarsson veiðimaður og Jóhannes Sturlaugsson líffræðingur munu ávarpa fundinn. Þá mun Bubbi Morthens taka lagið. Bubbi hóf fundinn á að spila tvö lög. Inga Lind Karlsdóttir stýrði fundinum og tók til máls. Jóhannes Sturlaugsson líffræðingur tók til máls. „Vér mótmælum öll!“ sagði Jóhannes í ræðu sinni við mikinn fögnuð.Þegar Guðlaugur Þór Þórðarson umhverfis-, orku- og loftslagsmálaráðherra tók til máls tóku sumir fundarmenn upp á því að púa á hann. Í viðtali við fréttamann að ræðu lokinni sagði hann sjókvíaeldin ekki vera mál á hans borði, en játaði í leið að um alvarlegt mál væri að ræða, og vísaði til ætlaðs brots Artic Sea Farm.Undir lok fundarins gaf Inga Lind mótmælendum þau fyrirmæli að hella „lúsaeitri“ yfir Austurvöll úr flöskum sem skipuleggjendur höfðu raðað upp við sviðið.\")[0][\"summary_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Þetta módel getur skilað mjög góðu og hnitmiðuðu yfirliti yfir texta, svo lengi sem þeir séu skrifaðir eins og fréttir, þ.e. virðist vera 3. persónu frásögn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 128, but your input_length is only 33. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Þorvaldur Tumi Baldursson, maður á þremur hunda og vinnur í búð. Hann er tölvunarfræði nemandi og kennari.\n"
     ]
    }
   ],
   "source": [
    "non_sum = input(\"Sláðu inn texta sem þú vilt stytta: \")\n",
    "print(summarizer(non_sum)[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
