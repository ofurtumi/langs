{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7b64845-0bd9-48dd-b823-a921b6c31daa",
   "metadata": {},
   "source": [
    "# Heimadæmi 1 - TÖL025M Inngangur að máltækni\n",
    "\n",
    "Þorvaldur Tumi Baldursson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ef5b67-e32b-4b4d-b419-e2ab46d297d3",
   "metadata": {},
   "source": [
    "## 1. Gagnasafn\n",
    "Gagnasafnið notast við 888 texta og ljóð úr íslenskum dægurlögum fengin af [þessari](https://sol.heimsnet.is/!GSS_ymislegt/Lagatextar2.htm) síðu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0356850a-6321-45a5-b6dd-57df399e8795",
   "metadata": {},
   "source": [
    "## 2. Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c540871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def tokenizer(file):\n",
    "    with open(file) as f:\n",
    "        txt = f.read().replace(\"\\n\", \" \")\n",
    "\n",
    "    words = re.sub(r'\\.\\.+', '', txt)\n",
    "    words = re.sub(\"(.)([\\,\\.\\:\\!\\/\\?\\\"\\'\\„\\(\\)\\…\\´])[^.]\", r\"\\1 \\2 \", txt).split()\n",
    "    words_lower = list(map(lambda w:w.lower(), words))\n",
    "\n",
    "    data=dict()\n",
    "    data[\"raw\"] = txt\n",
    "    data[\"words\"] = words\n",
    "    data[\"words_lower\"] = words_lower\n",
    "\n",
    "    data[\"unique\"] = sorted(dict(Counter(words)).items(), key=lambda x:x[1])\n",
    "    data[\"unique_lower\"] = sorted(dict(Counter(words_lower)).items(), key=lambda x:x[1])\n",
    "\n",
    "    data[\"unique\"].reverse()\n",
    "    data[\"unique_lower\"].reverse()\n",
    "\n",
    "    return data\n",
    "\n",
    "data = tokenizer(\"./data/log.txt\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7156362-8efc-4360-b1ca-73d1d34f015a",
   "metadata": {},
   "source": [
    "### a) Fjöldi tóka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3bcedfb-ba53-4faf-b2c6-5075757676e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100224"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[\"words\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad74e663-30fb-4475-9071-418fba895cee",
   "metadata": {},
   "source": [
    "### b) Fjöldi einstakra tóka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab46741f-8b6d-43f7-90fa-7752e47d804f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15996"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[\"unique\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3a6b67-c3f1-4e6d-b89d-f446301ecdb7",
   "metadata": {},
   "source": [
    "### c) 10 algengustu tókar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c59c8242-5a1f-4ee1-b041-5da6915f4f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',': 6965,\n",
       " '.': 6255,\n",
       " 'og': 3964,\n",
       " 'í': 2065,\n",
       " 'er': 1855,\n",
       " 'á': 1690,\n",
       " 'að': 1681,\n",
       " 'ég': 1475,\n",
       " 'sem': 971,\n",
       " 'við': 840}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(data[\"unique\"][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ea8908-cf16-49f8-80c9-7e6d061858b9",
   "metadata": {},
   "source": [
    "### d) 10 algengustu tók eftir lower()\n",
    "það er munur á `unique` og `unique_lower` en röðin helst þó eins fyrir efstu 10 tókin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e216e71-812a-41e2-9abc-d5582c6360d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',': 6965,\n",
       " '.': 6255,\n",
       " 'og': 4354,\n",
       " 'í': 2265,\n",
       " 'ég': 1927,\n",
       " 'er': 1901,\n",
       " 'á': 1785,\n",
       " 'að': 1721,\n",
       " 'sem': 983,\n",
       " 'við': 974}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(data[\"unique_lower\"][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397a2541-22bf-4d67-9856-108a33dc80a9",
   "metadata": {},
   "source": [
    "### e) lengri en 8 stafir\n",
    "top 10 og fjöldi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be141eb8-f8b0-4a6e-a1d9-0a9a6fe6145d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('guðmundsson', 41),\n",
       " ('ólafsson', 35),\n",
       " ('ólafsdóttir', 33),\n",
       " ('drip-drop', 32),\n",
       " ('drottinn', 28),\n",
       " ('eitthvað', 28),\n",
       " ('kristján', 26),\n",
       " ('sigurður', 24),\n",
       " ('hjartans', 24),\n",
       " ('steingrímur', 21)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eight_plus(l):\n",
    "    return [x for x in l if len(x[0]) >= 8]\n",
    "\n",
    "ep = eight_plus(data[\"unique_lower\"])\n",
    "print(len(ep))\n",
    "ep[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428b7730-1c0f-44d4-815a-8952094a91c3",
   "metadata": {},
   "source": [
    "### f) lengsta tók"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a647b5c6-58e2-44ad-8fd7-ba25b9992ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tiggiddi-taggi-taggi-taggi-dúm-dúm-dúm'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(data[\"words\"], key=len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd1ea2-3404-4c29-8a75-f84e1f24c65e",
   "metadata": {},
   "source": [
    "## POS-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "930388b9-1909-4279-ac60-3f54d25c9767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reynir import Greynir\n",
    "g = Greynir()\n",
    "parsed_data = g.parse(data[\"raw\"][:20000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24125c55-231f-4fec-b6a0-7679f9184e68",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a193d2c-9e91-41d3-827e-fddf0cd9bf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'so': 321,\n",
       " '': 249,\n",
       " 'kk': 179,\n",
       " 'fs': 158,\n",
       " 'ao': 142,\n",
       " 'st': 141,\n",
       " 'hk': 128,\n",
       " 'lo': 125,\n",
       " 'pfn': 122,\n",
       " 'kvk': 117,\n",
       " 'fn': 75,\n",
       " 'entity': 33,\n",
       " 'nhm': 24,\n",
       " 'to': 4,\n",
       " 'abfn': 3,\n",
       " 'gr': 2,\n",
       " 'töl': 2,\n",
       " 'uh': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skilar nafnorðum skiptum niður eftir kynjum\n",
    "def top_cats_gender(sentences):\n",
    "    if sentences is None: \n",
    "        return None\n",
    "    \n",
    "    scores = {}\n",
    "    for s in sentences:\n",
    "        if s.categories is None: \n",
    "            continue\n",
    "            \n",
    "        for cat in s.categories:\n",
    "            if cat in scores:\n",
    "                scores[cat] += 1\n",
    "            else:\n",
    "                scores[cat] = 1\n",
    "    \n",
    "    return dict(sorted(scores.items(), key=lambda x:x[1])[::-1])\n",
    "\n",
    "top_cats_gender(parsed_data[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3796163-2481-448e-a149-f97b5eab08f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': 427,\n",
       " 'so': 321,\n",
       " '': 249,\n",
       " 'fs': 158,\n",
       " 'st': 133,\n",
       " 'lo': 125,\n",
       " 'pfn': 122,\n",
       " 'ao': 105,\n",
       " 'fn': 75,\n",
       " 'eo': 37,\n",
       " 'nhm': 24,\n",
       " 'person': 24,\n",
       " 'stt': 8,\n",
       " 'sérnafn': 5,\n",
       " 'to': 4,\n",
       " 'abfn': 3,\n",
       " 'gr': 2,\n",
       " 'töl': 2,\n",
       " 'uh': 1,\n",
       " 'entity': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skilar nafnorðum sem sér flokki\n",
    "def top_cats_no(sentences):\n",
    "    if sentences is None: \n",
    "        return None\n",
    "    \n",
    "    scores = {}\n",
    "    for s in sentences:\n",
    "        if s.terminals is None: \n",
    "            continue\n",
    "\n",
    "        for t in s.terminals:\n",
    "            cat = t.category\n",
    "            if cat in scores:\n",
    "                scores[cat] += 1\n",
    "            else:\n",
    "                scores[cat] = 1\n",
    "    \n",
    "    return dict(sorted(scores.items(), key=lambda x:x[1])[::-1])\n",
    "\n",
    "top_cats_no(parsed_data[\"sentences\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4422b2a-9aa7-475b-a0e9-8654d6402657",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24aa896d-0c2f-44cc-b9d7-26d1c9c07b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'á': {'ao', 'aþ', 'nhfn', 'nveo', 'sfg3en'},\n",
       " 'öllum': {'fohfþ', 'fokeþ', 'fovfþ'},\n",
       " 'brún': {'nven', 'nveo', 'nveþ'},\n",
       " 'dansa': {'nkfe', 'sfg3fn', 'sng'},\n",
       " 'nótt': {'nven', 'nveo', 'nveþ'},\n",
       " 'tún': {'nhen', 'nheo'},\n",
       " 'fín': {'lhfnsf', 'lvensf'},\n",
       " 'fyrir sunnan': {'aa', 'ao'},\n",
       " 'stóra': {'lheovf', 'lveosf'},\n",
       " 'neitt': {'fohen', 'foheo'},\n",
       " 'góða': {'lkeevf', 'lveosf'},\n",
       " 'skal': {'sfg1en', 'sfg3en'},\n",
       " 'fimm': {'tfhfe', 'tfkfe'},\n",
       " 'fylgd': {'nveo', 'nveþ'},\n",
       " 'Re': {'nhee-s', 'nhen-s'},\n",
       " 'ró': {'nven', 'nveþ'},\n",
       " 'haga': {'nkeo', 'nkeþ'},\n",
       " 'ertu': {'sbg2en', 'sfg3fþ'},\n",
       " 'fyrsta': {'lkfosf', 'lveosf'},\n",
       " 'Hver': {'fsken', 'fsven'},\n",
       " 'blaka': {'nven', 'nvfe'},\n",
       " 'bí': {'lkenof', 'nhen'},\n",
       " 'kvöld': {'nhen', 'nheo'},\n",
       " 'gengu': {'lhfnvf', 'sfg3fþ'},\n",
       " 'gott': {'lhensf', 'lheosf'},\n",
       " 'Hlíð': {'nveo-ö', 'nveþ-ö'},\n",
       " 'Anna': {'nven-m', 'nven-s'},\n",
       " 'fyrir': {'ao', 'aþ'},\n",
       " 'minn': {'feken', 'fekeo'},\n",
       " 'yfir': {'ao', 'aþ'},\n",
       " 'mitt': {'fehen', 'feheo'},\n",
       " 'hönd': {'nveo', 'nveþ'},\n",
       " 'öll': {'fohfn', 'fohfo'},\n",
       " 'nokkrum': {'fokfþ', 'fovfþ'},\n",
       " 'Í': {'ao', 'aþ'},\n",
       " 'mun': {'sfg1en', 'sfg3en'},\n",
       " 'þér': {'fp2eþ', 'fp2fn'},\n",
       " 'fer': {'sfg1en', 'sfg3en'},\n",
       " 'þín': {'fehfo', 'fp2ee'},\n",
       " 'heiði': {'nheo', 'nkeþ'},\n",
       " 'var': {'sfg1eþ', 'sfg3eþ'},\n",
       " 'í gegnum': {'aa', 'ao'},\n",
       " 'það': {'fphen', 'fpheo'},\n",
       " 'hún': {'fpven', 'nkeo'},\n",
       " 'eina': {'lhenvf', 'tfveo'},\n",
       " 'sér': {'fpxeþ', 'sfg3en'},\n",
       " 'með': {'ao', 'aþ'},\n",
       " 'í': {'ao', 'aþ'},\n",
       " 'við': {'ao', 'fp1fn'},\n",
       " 'hann': {'fpken', 'fpkeo'},\n",
       " 'eins': {'lkfnof', 'lvenof'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def num_combs(sentences):\n",
    "    multis = {}\n",
    "\n",
    "    for s in sentences:\n",
    "        if s.tree is None: continue\n",
    "        for c in s.tree.leaves:\n",
    "            if len(c.variants) > 0:\n",
    "                if c.text in multis:\n",
    "                    if isinstance(c.ifd_tags, list):\n",
    "                        multis[c.text].add(c.ifd_tags[0])\n",
    "                    else:\n",
    "                        multis[c.text].add(c.ifd_tags)\n",
    "                else:\n",
    "                    multis[c.text] = set(c.ifd_tags)\n",
    "    return dict(sorted(dict(filter(lambda x: len(x[1]) > 1, multis.items())).items(), key=lambda x: len(x[1]))[::-1])\n",
    "\n",
    "combs = num_combs(parsed_data[\"sentences\"])\n",
    "combs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1866f55-5d5b-46c5-b2f8-b16a43f211f3",
   "metadata": {},
   "source": [
    "### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b88751c-87a8-42bc-82f6-064fd923e516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'á': {'ao', 'aþ', 'nhfn', 'nveo', 'sfg3en'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(filter(lambda x: len(x[1]) == len(combs[\"á\"]), combs.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e800389f-368e-4bbb-9c12-d0f2699d2c7f",
   "metadata": {},
   "source": [
    "### d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6c21cfe-c806-46e7-bca0-4a14127a2f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('.', ''): 149,\n",
       " (',', ''): 83,\n",
       " ('og', 'st'): 65,\n",
       " ('er', 'so'): 38,\n",
       " ('á', 'fs'): 34,\n",
       " ('þú', 'pfn'): 32,\n",
       " ('í', 'fs'): 32,\n",
       " ('að', 'nhm'): 24,\n",
       " ('með', 'fs'): 21,\n",
       " ('áttu', 'so'): 18}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# þessi flott :)\n",
    "dict(sorted(dict(Counter([i for sub in [[(tok.text, tok.cat) for tok in leaf] for leaf in [s.tree.leaves for s in parsed_data[\"sentences\"] if s.tree is not None]] for i in sub])).items(), key=lambda x: x[1])[::-1][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd74a42a-8ee8-40f1-bd2e-7e12275dbf42",
   "metadata": {},
   "source": [
    "### e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2294de99-d867-424b-9b20-57d0245e52d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('st', 'pfn', 'so'), 35),\n",
       " (('', 'st', 'pfn'), 33),\n",
       " (('pfn', 'so', 'so'), 24),\n",
       " (('so', 'nhm', 'so'), 21),\n",
       " (('fs', 'kk', ''), 20),\n",
       " (('so', 'so', 'nhm'), 18),\n",
       " (('', 'ao', 'so'), 16),\n",
       " (('', 'kk', 'so'), 14),\n",
       " (('so', 'ao', 'fs'), 14),\n",
       " (('lo', 'kvk', ''), 14)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def get_trigrams(t):\n",
    "    trigrams = []\n",
    "    for i in range(len(t) - 3):\n",
    "        trigrams.append((t[i], t[i+1], t[i+2]))\n",
    "    return trigrams\n",
    "\n",
    "top_trigrams = get_trigrams([i for sub in [[tok.cat for tok in leaf] for leaf in [s.tree.leaves for s in parsed_data[\"sentences\"] if s.tree is not None]] for i in sub])\n",
    "sorted(Counter(top_trigrams).items(), key=lambda x: x[1])[::-1][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4906f6-d1ed-4731-bad0-a03c95d08270",
   "metadata": {},
   "source": [
    "### f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "966f8bb1-2a50-41e5-9349-c1f72f49d8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fór     : so\n",
      "í       : fs\n",
      "banka   : no\n",
      ",       : \n",
      "ekki    : ao\n",
      "banka   : no\n",
      "\n",
      "\n",
      "Fór     : so\n",
      "í       : fs\n",
      "banka   : no\n",
      ",       : \n",
      "ekki    : no\n",
      "banka   : no\n",
      "á       : so\n",
      "hurðina : no\n"
     ]
    }
   ],
   "source": [
    "# ruglar sagnorðinu banka og heldur að það sé nafnorðið banka, \n",
    "# það náttúrulega meikar sense en er ekki rétta meiningin\n",
    "confusion = g.parse_single(\"Fór í banka, ekki banka\")\n",
    "for l in confusion.tree.leaves:\n",
    "    print(f\"{l.text:8}: {l.tcat}\")\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "# jafnvel þótt við bætum við smá samhengi þá ruglast reynir litli l\n",
    "confusion = g.parse_single(\"Fór í banka, ekki banka á hurðina\")\n",
    "for l in confusion.tree.leaves:\n",
    "    print(f\"{l.text:8}: {l.tcat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e3c254-2f71-4b2f-b2fd-05c04ab776ab",
   "metadata": {},
   "source": [
    "## 3.\n",
    "### 4.1) \n",
    "> Compare the four different methods of gathering data that were discussed in class, i.e.\n",
    "manually gathering data, scraping the internet, using crowd-sourcing methods and\n",
    "using NLP systems. What are their pros and cons? Which one would you pick if you\n",
    "needed to create a training corpus from scratch?\n",
    "\n",
    "- Manually gathering data\n",
    "Can be very time consuming but if done well can produce very good data, however can also be pretty hard to do correctly\n",
    "\n",
    "- Scraping the internet\n",
    "Can save a lot of time since the data is very plentiful, however can also yield incorrect or badly formatted data\n",
    "\n",
    "- Using crowd-sourcing methods\n",
    "If the correct crowd is used can be one of the most time efficient and valuable data gathering methods, however if the crowd is not very good the data won't be very good either\n",
    "\n",
    "- NLP systems\n",
    "The same pros and cons can be applied here, mostly though if the raw data is crap the formatted data will be crap\n",
    "    \n",
    "### 4.2) \n",
    "> Sometimes, we need to anonymize our data in order to protect the privacy of the\n",
    "people that are mentioned. This can be very important and we should always consider\n",
    "whether or not our data can harm the people mentioned in any way before publishing\n",
    "a language resource. However, we are not able to train some systems on anonymized\n",
    "data if they are to be able to perform the tasks they are meant to solve. What type of\n",
    "systems could they be?\n",
    "\n",
    "These systems could be related to social media, tracking different peoples interest in something, Then we need to be able to recognize specific people and therefore can't anonimize them.\n",
    "\n",
    "### 4.3) \n",
    "> Discuss briefly (approximately 100-200 words) what implications it can have if the data\n",
    "we use to train language and AI models contains prejudice. What could potentially\n",
    "happen (or what has already happened in the past)? Name an example of a system\n",
    "whose performance could be influenced by the bias.\n",
    "\n",
    "The data we use can affect our applictaion in many ways. This becomes very important to look out for when making applications used directly by people. An example of this could be Tay, an AI chatbot launched by Microsoft to Twitter. Tay was described as *an experiment in conversational understanding*[ meaning that users could interact with the bot and it would learn from their responses. This can be seen as an example of biased data since 24 hours later Tay was telling people that \"Hitler was right\" and other things as horrible. A prime example that giving people the ability to influence a model directly will very likely corrupt it in some way.\n",
    "> Reference:\n",
    "> \n",
    "> The Verge. (2016, March 24). Microsoft's AI chatbot Tay goes dark after racist, sexist tweets.\n",
    ">\n",
    "> https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist\n",
    "\n",
    "### 4.4) \n",
    "> Did you run into any problems solving this homework assignment? If so, please\n",
    "describe them here.\n",
    "\n",
    "Ég átti í smá veseni með documentationið hjá Greyni en um leið og ég komst aðeins inn í það var þetta bara smá python snúningur."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
